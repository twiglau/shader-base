# 混合测试  
* 混合就是针对的是物体透明度处理的一种技术.比如现实生活的玻璃窗, 我们能通过透明度看穿物体.

* 透明物体分为完全透明, 也就是让所有的颜色通过透明度为 0, 和半透明, 也就是让颜色通过同时也会带有自身的颜色. 透明度通过 alpha 值来决定, 也就是颜色 rgba 的 a 分量.

* 对于大多数 3D 物体来说, 采用的都是不透明的贴图, 也就是透明度为 1 的贴图, 它们只需要根据深度检测, 决定最终的片段呈现的是哪一个物体即可. 物体深度与深度缓冲中的深度,根据指定 对比函数进行对比测试, 测试失败的片源都会被丢弃,  而透明的物体单纯用深度测试这一套规则就不合理.容易出现透明物体渲染出现错误的现象. 所以我们需要告诉 WebGL 如何处理带有 alpha 信息的纹素, 也就是组成纹理图像的像素.

* 混合测试分为两个步骤:  
> 一个透明度测试; 
>> 如果一个图片并不需要半透明, 只需要根据纹理颜色值显示一部分或者不显示一部分. 没有中间情况.
>> 如带有一部分完全透明部分的图片, 如果不对完全透明部分纹素进行处理的话, 默认就会取纹素自带的颜色呈现[如透明部分呈现白色,不是透明的]. 这显示不是想要的效果.
>> 如果要解决这里显示错误的问题,让纹素的透明信息被识别, 只需要限定一个阈值. 将阈值与纹理 alpha 值进行比较, 丢弃掉阈值限制内的片段 或者 像素就好.GLSL 给了我们 `discard` 的命令. 一旦被调用, 它就会保证片段不会被进一步处理. 
```
CCEffect %{
        ...
        properties: &props
        mainTexture: { value: white }
        mainColor:   { value: [1, 1, 1, 1], editor: { type: color }}
        alphaTest: { value: 0.5 } # alpha阈值测试
    - name: transparent
      passes:
      - vert: general-vs: vert #builtin header 
        frag: unlit-fs:frag
        blendState:
          targets:
          - blend: true
            blendSrc: src_alpha
            blendOst: one_minus_src_alpha
            blendSrcAlpha: src_alpha
            blendOstAlpha: one_minus_src_aplha
        properties: *props
}%

CCProgram unlit-fs %{
    precision highp float;
    #include <output>
    #include <cc-fog-fs>

    in vec2 v_uv;
    uniform sampler2D mainTexture;

    #if USE_ALPHA_TEST
      uniform Alpha {
          float alphaTest;
      };
    #endif

    uniform Constant {
        vec4 mainColor;
    };

    vec4 frag () {
        vec4 col = mainColor * texture(mainTexture, v_uv);
        // 这里处理当纹理的 alpha 小于 alphaTest 值的时候
        #if USE_ALPHA_TEST 
        if(col.a < alphaTest){
            discard
        }
        #endif
        CC_APPLY_FOG(col);
        return CCFragOutput(col);
    }

}%
```  
* 以上丢弃片段对我们来说很轻松, 但是更多时候我们是希望看到物体之间相互作用的效果, 它无法像渲染不同名物体 或者 完全透明物体一样直接丢失片段, 而在必要情况下, 需要同时渲染多个透明度级别的图像. 因此需要启用混合. 

* 一个透明度混合, 启用混合是需要关闭深度写入, 而在进行深度检测时, 会对相对应的像素进行替换. 是一个非A即B的过程, 而混合方式始终遵循着这样一个方程:  
```
color(RGBA) = ((sourceColor * sfactor) + (destinationColor * dfactor)).RGBA
```  
> 其中 sourceColor 代表源颜色向量.这是源自纹理的颜色向量. 
> destinationColor 则是目标颜色向量, 这是当前存储在颜色缓冲中的颜色向量. 
> sfactor 则是源因子值. 指定 alpha 值对源颜色的影响. 
> dfactor 则代表目标因子值, 指定了 alpha 值对目标颜色的影响. 
> 在混合中也有跟深度测试一样的函数 blendFunc, 是用于混合的混合函数 
```
void blendFunc(GLenum sfactor, GLenum dfactor);  
```  
> 例子: 带有透明度图片 + 背景 => 3D场景中.
>> 1. 尝试开启混合,并设置混合因子. 编辑器: Blend ☑️ , BlendSrc[源因子] = SRC_ALPHA[让图像采用源颜色] , BlendDst[目标因子] = ONE_MINUS_SRC_ALPHA[代表 1 - 源颜色]
>>> 计算: 假设源颜色为:玫红色, 透明值为 0.9, 0, 0.6, 0.5. 而颜色缓冲的值为 绿色: 0, 1, 0, 1, 根据刚刚配置的混合因子.计算方式如下:
>>>  `color(RGB) = (0.9, 0, 0.6)*0.5 + (0, 1, 0)*0.5     color(A) = 0.5*1 + 1*0`
>> 2. 也可以通过 `gl.blendEquation` 来修改计算方式. 它接受一个参数 mode, mode 参数可以配置为 相加, 相减 或者 反过来 相减等等. 

* 多物体的场景下, 需要进行混合的物体要开启深度测试 或者 执行深度写入吗? 透明物体和半透明物体的渲染顺序应该是怎样的? 正确的做法,大致原则如下:
> 首先, 先绘制所有不透明的物体.
> 接着, 再对所有透明的物体排序. 采用的是观察者视角, 也就是距离相机的远近来进行排序. 大多数情况下,不开启深度测试, 最后我们再按照从远到近的顺序来绘制透明的物体. 
> 在 Cocos Creator 3.x 里, 我们也是遵循着这样的原则绘制的. 但针对第二点的话, 重点标准下 "大多数情况下", 为还有特殊情况, 如: 两个带有穿插效果的半透明物体, 物体A 的上半部分距离相机更近, 物体B 的下半部分距离相机更近. 它们之间呈现 X 形状. 所以会出现物体 A 的下半部分被物体 B 的下半部分遮挡. 物体B 的上半部分也是一样.  但是相机识别的是物体的深度, 所以最终会出现一个物体表现出异常的情况. 这种情况无法避免, 最理想的肯定是 引擎能做 `网格分离`, 然后这个时候 半透明物体进行深度检测分离数据, 但可以不进行深度写入.  这样就不会丢弃片段. 

# 模板测试 -面剔除: 部分提到的正面和背面
* 面剔除是在图元装配阶段就进行的, 为了较少进入光栅化的图元数量, 加速渲染过程. 
* 一个带透明度[各个面]的立方体,有了混合效果之后,立方体地面和背面都不见了?
> 既然一个面是透明的, 就意味着既能透过它看到后面的场景, 也能看到它内部的结构. 但现实情况,好像不是这么回事. 这是因为引擎默认剔除了 渲染背面, 所以无论我们怎么旋转, 都能看到物体的正面, 而无法看到它背面的样子. 因此我们需要同时开启正面 和 背面的渲染. 在这我们可以通过 一个 `CullMode` 来设置, `CullMode` 在 `resterizerState` 状态设置下.  
> 原理: 就是环绕顺序, 当我们在定义一个三角形顶点的时候, 也记录了 一组顶点索引数据. 这个顶点索引数据的设置其实是有讲究的. 默认底层将逆时针方向定义为正方向. 因此,提供顶点索引方式按照逆时针提供即可. 如果我们的正面数据提供的是 逆时针, 反之背面就是顺时针. 剔除别面则是按顺时针提供的顶点数据不显示. 此处设置为 `none` 则是不剔除. 因此不管顺时针还是逆时针都可渲染. 
>> 注意: 逆时针还是顺时针, 这里都是按照提供的顶点顺序而决定的, 不是观察者视角.